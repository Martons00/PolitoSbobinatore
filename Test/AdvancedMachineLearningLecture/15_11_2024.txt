The first part of the lecture is about CVPR, computer vision and pattern recognition. The second part is about how to present a paper to an audience of more than 2000 people. The third part is a discussion of how to write a CVPR paper. The fourth and final part is the introduction of the paper, which is the part where the authors explain why they are writing this technical report and why it is important to solve the task? So why is the problem is relevant? And why is it relevant now? And then the next step is something that you need to explain, right? So everything should work. I'm going to start sorry for the terrible delay. Okay, let's do like this. Yeah, just to share some experience. Last night has been the crazy night, the craziest night of the year. You see when you are going to read the papers, some of them comes from a conference which is a top conference in computer vision. So my lab, we submitted eight papers, that's been just one hour sleeping. So it was very, very tough. That's happened every year, more or less in this period. So when it's exciting, besides being a little bit tiring, but it's okay. So for today, there's still some stuff that we need to finish from the previous lecture. But before going there, since a lot of people asked about the paper presentation, so we'll go a bit through some advice aboutHow to read a paper.
The real way in which you should read a paper actually is title, abstract, introduction, distilling the relevant information. And then what you do is that you go through the figures and the tables of the results, and then you go to the conclusion. So in the very first pass through the paper, you might not focus directly on the related work. It might be quite boring in a sense that really is just referring to previous literature. So it might be boring, so it might not immediately attract your attention. And indeed, I mean, I might suggest you do not read it during your first pass on the paper. So do it in the second pass. But in the beginning, for sure. So I expect that, for instance, a CDPR paper has this kind of structure because this is evaluated. Because for me, it was irrelevant. Whatever was the structure, I was expecting the method to work because we were more going to go to architecture in details rather than going to the architecture itself. So usually you expect to see a figure with the structure of the architecture, the logic of the model, and the flow. What you expect as you do as a reader of the paper is to provide as input as    what you expect the paper to do. But I also try to connect to concept, very high level concept, right? So they try to explain why the task is important, maybe referring to some high level objective that is not targeted directly in this paper.
In every paper, there should be a description of what the model is trying to optimize. It's always there. Even if it's not explicit in the method section, maybe the loss function is somehow hidden in the appendix supplementary. If there is something that you don't know, I mean, a strange metric that you have never seen before, search for that, Google it, try to follow the references. So these are two of the most important things you have to understand out of the paper. So look at the tables, look at plots,try to understand what's the metric that is measured there, and try to make sense out of it. Okay, so experiments, then, in terms of conclusion, we already discussed them references, well, references is towards the end of thePaper. And so you see here, for instance, there's a 30, which means that you understand what was the content of the previous paper here. And it's a format, the structure is usually the same. So yeah, the idea is that you read a paper in multiple passes, you read the title, the abstract, the title of the article, and so on. So, okay. You can have a paper, let's say that this is the structure of a CVPR paper, some of the papers are like CVPR has two columns, some other papers are just one column, but it's just a format. So as we go through the figures, as we s s s    s, we will look at figures, plots, and results.
The appendix and the supplementary is not, I mean, it is not mandatory. But it might be useful, again, if there is something that you did not understand in the paper and you want to search it. So here it says read, but skip parts that do not make sense. So you have to subselect the most important part. And then usually, besides, of course, reading a paper to do the presentation for the class, in the future, if you find yourself reading a. paper, then of course you ask yourself, which kind of the information. that is in the research. So, this is a university course. But the problem is that we can't teach you as much as we can in the hours that we have for the course, or at least at least what we expect you to become y       - we have to become a better reader. So we try to make sure that in particular with the pass, I try to try to understand the concept. So then even if the exact detail of the laws, you immediately don't understand it, then at least you have tried to understanding the concept, right? So it's quite complicated to say a priori what is that it does not makes sense. But still, Imean, they are relevant if, ofcourse, you want. to implement the model. So that is just up to you if you think you need it. But in general, you are not, even though the paper comes with this extra material, it's not mandatory to be read.
The course is just one tenth of everything that you might need for your future work, right? So you have to be able to search for the sources by yourself. So try to understand what is the part of the paper that will be useful for your work, for your task. And then maybe you can reuse it for your project. And it might be one variant of the project that you propose yourself over the list of things that are there, described in the project itself. And usually this is very well evaluated. So it's very, I mean, highly appreciated the fact that you found some connection, and you think that something that you read in that paper could be used for a new problem. Okay, so this is the kind of procedure we are thinking about when reading a paper. And the following step is how to present those such paper. So let me explain. So now we have an very first group of paper that has been assigned, they are related to architecture. But later on, we will have group of papers related to anomaly detection, and on. So my suggestion is to dedicate at least one slide, if not two, to the description of the problem. But if you're the first, it means that all the people behind you, so after you, practically will discuss exactly the same problem after you. And you hav    hav to be a lifelong learner. And so this kind of exercise that we are doing is also something that can be useful in the future.
When presenting a paper to an audience, you want to set the stage, right? You want to explain what was the kind of task we are dealing with. Try to keep a good level of, let's say, in terms of details, because your goal for the presentation is to understand. But then, when you present the paper, you have a different kind of, say, objective, which is that of letting the audience understand, okay, the work. Before presenting the, the table of the results, make sure that it's very clear. So we have x, y, z, gamma, alphabet, whatever. So it's welcome, but make sure in your speech, that you are explaining it with your voice, I mean, in your voice. I expect that I forgot that I really forgot, again, when I was talking to you. I'm sorry, I didn't mean to forget. I was trying to say something else, but I'm not sure what it was, so I'll try to explain it again. I'll be back in a few minutes with the next part of the talk. I hope you'll be able to watch it on CNN.com or CNN iReport.com. Back to Mail Online home. back to the page you came From. The page you were coming from. Click here for more information on how to present a paper at a conference or a conference and how to get involved in a conference by emailing jennifer.smith@mailonline.co.uk.
When you create a slide, besides the title of the paper that you are discussing, the authors or the group or the research university from which the team is, the origin of the team, and the conference, make sure, of course, to put your names, right? So who is presenting? And put the names in the order in which you are going to do the presentation. So please use exactly the same list, I mean, the same order inWhich you're going to present. So other important advices, don't get over time. If you have something, you have a time to do it. Do not overload the slides with text, so you can have the extra notes in your slides. You are allowed to have your presentation and one screen on the other screen in the other room. Of course, you are not allowed to do that, but of course they are not there for there. So I expect three minutes each during the presentations. That is really important. It's one of the things that they evaluate. So, that's important again, in the future, you might have any kind of assignment in your work to do again, because you have to stick to the basis of that. Right? So, okay, now final, let's say, high level advice. So by looking at the introduction, so considering what the authors promised, and maybe also which kind of high level problem they were trying to solve, then from the introduction to the conclusion, you went through all the steps. And then you realize that practically out of the huge problem that they were mentioning at the beginning, they solved one very small piece.
Don't memorize. Your goal is not to just memorize stuff and repeat them by heart. You are not a parrot. And it's okay. I mean, if there's something that you didn't understand, it's fine. You just put it in the slide. So that's it for the paper presentation or paper discussion, paper reading and paper presentation. So questions should be clear enough. So if you follow exactly these advice, it will not be too difficult. The only difficulty that I think it's, but that's reasonable, is the fact that then you will have to present in nine minutes. Okay, that's a challenge. That's that the part on which you have to put a bit of effort, because you have. to understand again, the level of details at which you want to present everything to stay in the nine minutes, and so on. Okay. So this said, I would close this part of the presentation. And we can get to the remaining parts of the lecture of last time. Okay? Last time we discussed about the the current neural networks. We got to the explanation of the long short term memory, right? So the architecture that I know as to elaborate on sequences, even in case of very long sequences. And thanks to the fact. that we have these extra path inside the architecture inside the logic and so of each module, we have practically a direction through which the gradient can flow from the beginning to the end, and allows to keep the memory right. Still, when going back towards the beginning through the back propagation, we are not forgetting because we are keeping the most of the gradient flowing.
The idea of attention is a concept that has been introduced exactly to elaborate on very long sequences. So, this is the typical standard, let's say procedure or strategy that we expect when we deal with another name. And the encoder at the end of the day is just. The whole process here that encodes information, and then the output of this network becomes the input of a second part, which works as a decoder. But the problem is that we are not doing the best that we can. The, this can be done. But this works when we are dealing with short sequences. Okay, so when instead the sequence is very long, this makes the life of the decoder difficult. And this is fixed, which is true that is what has been produced. But it's still, it's just to constrain condition, right, does it not help the network. And so, this works, of course, you already see that with respect to what we discussed last time I added something different because I have both the context itself which is the hidden state and something else which is produced through a fully connected layer. Do you want to come here and explain. We have an input, we have a hidden state. And we have this every hidden state is practically taking as input, both the new input and the output from the previous step. So if I do like that I practically have two outputs, and this becomes the first hidden state so the. initial decoder state.
So, yeah, coding everything just inside the sea is not enough in this case. So we might try to define a new kind of context factor that helps the following steps of the decoder. Okay, so we can consider the outputs of what we discussed before so this s zero that we said was obtained through a fully connected layer out as over the hidden state so the output of the previous hidden state. So this is a hidden state vector. What you can do is try to evaluate the relation between these vector and vectors of the hidden states. So then what you do well, you produce the output we said, and then you have a new s, which is s one, and you red the same. So you can consider a sort of alignment score, a function that evaluates the attention indeed that tells you how well is these vector aligned with the hiddenState intermediate. So yeah, so these are the attention weights that we get through this process. And now we do something that apparently is complicated about the truth is that it is not, because what we are doing here is just rescaling the age vectors by the score that we produce here. So, and once we obtain all these rescaled age, we just linearly combine them together with some them, and they will be the new see. Okay. So the context vector now is a linear combination of the Rewaited age, where the weights depend on exactly what the network discovered to be relevant for s zero. And so for instance we expect that for the word is Thomas,  which is a verb in Spanish. Well, we are expecting that are eating our are at least.
The network is pre trained on ImageNet, for instance, you will pass the sample inside the network to produce a vector. Now, before getting to the final vector I mean to the fully connected layers, we know that the structure of the output of a convolutional layer has a spatial dimension. So what we can do is that we create patches of this tensor. And these patches are all equally important but if you read them from left to bottom to right, then it's like creating a sequence. And so this becomes the logic of attention applied to elaborating signals. But the truth, of course this is a tension it's analyzing these correspondences between the encoder and the quarter part of the network the sequences provided as input and generated. So, the order make the order then we rediscover it by looking at the attention matrix true. So it's but that is the result. Okay, so it's the result of the procedure that indicates this correspondence between the order. And we know which we were using it in terms of context since we are just linearly combining everything. So this tells us something tells us that we can use this logic of Attention, even for data that are not sequential by nature. For instance, we said that given an image, we can always use a network as a feature extractor, right. So we, the network isPre trained on imageNet,  for instance,. you will passed the sample into the network and it will produce a vectors.
The attention weights matrix can be used then to look at the original image of course the attention you elaborate it over convolutional. So you can see the feature map produced by the convolution so it's not directly the image right, but it's somehow representation of the image scaled down through the receptive field. Every single piece inside this feature map corresponds to a region inside the image so you can go back to the original input image. So, then, I mean, this procedure that we created has an extra advantage that being somehow inherently explainable, right, because we exploited attention we said so this step here, right. Okay, so in this way, we learned to generate a sentence so to produce a caption for an image. Next week we will discuss segmentation which is a different concept, but we had to start here because otherwise we would be talking about segmentation on the chalkboard. Thank you for listening to my talk. I just a second answer to your question on the question of how do we get a test zero from the image? Exactly as we said in the case of the sequence. How do we obtain a testzero from the images? Exactly. So we have these that this becomes your input you pass through some fully connected layer, and then you'll get a better result. And it is interesting because you might see that in practice really understood which part to attend, and it corresponds to the word on your on your sentence. Well, the work that the network is doing a good work.
The total operation is completed in: 1 minutes and 15.57 seconds
Unsupervised models are unsupervised approaches so we don't need labels for the data. We just have the data themselves and we try to define, let's say the density of the data so the probability distribution. We discussed about auto regressive approaches like pixel RNN and pixel CNN. We also approximate density method and we started mentioning the variational encoder but we didn't complete them so complete them today. And then the other family that of the implicit density function we have the generative adversarial models and we'll see them today too. We are going to start just the people from home if you can confirm that you're able to hear us. So I don't see anymore. Yeah, the bar is here. Here, how we just move it. If I'm able to move it, cannot. I don’t know what happened. Move the bar. It's here. Okay. And okay, great. I'll just increase the dimension here. So everything is feasible. Okay, so we're ready to start. So what is an auto encoder per se is an architecture that given an input recreate the same input so as output we want something that resemble it is as similar as possible to the input and the how do we impose it so which kind of objective are we targeting is just now to loss that takes a difference between what I provided as input and what I get as output. Now, yeah, it's the logic is the kind of power glass so we reduce the dimensionality will get it back.
The encoder can be trained with images without labels right so I just provide an input every create the same input so I don't need to know what is the semantic category in there. It means that I can train it on a lot of data. I mean, they can take just images from the web, millions of them train and out encoder. And then what I can do is I can just throw away to the quarter and use the encoding part as the pre training for any new downstream task. A new problem with specific data and maybe I have only a limited amount of them. So I use the encoder as a pre training part, and I just learned the remaining part of the network let's say the classifier maybe for a verylimited amount of samples. I can eventually fine tune and update the encoders. So the logic of the variation is that I'm trying to really capture the distribution of the data. Now the problem is that. Yeah, so this is the descriptor was telling you. There's a mouse there. Right so the Z is just this Latin factor descriptor of attributes and then I want out of the Z to produce an image. So, but this is a complicated task to do, because we don't know exactly so of course we can think about the network right so there will be some layers that brings me from the input Z to the output X. But again we have a question mark on how Z is defined. But I can introduce a decoder and the corner and theory I know how to design it.
In practice, so that will be extremely difficult for me to explain. So in practice we have two Gaussian distributions. And our goal is evaluating estimating the parameters of these distributions. In practice, the problem is that I can define by my own. What is the distribution of Z because this is my own choice. So these parts will be estimated by the encoder that will bring me, it will be sampling a Z from X. But this as you see is an estimate of P of theta. I don't have P of. theta under the exact definition. So, yeah, yeah. I should have this part, but I don’t have it. Right. Okay, so what happens here is what we have right so the logarithm of X. Now, I can always write the expectation value, I mean this expectation operator in front of these expression. There's no no Z here because this thing here is a constant with respect to this distribution. So I have this expression and I can use the rule they use and they can use this expression so now I have the equality. Okay. So this is the expression. And I'm free to do that. And this expression does not depend on Z, right? So I'm not yet able to reach Z through an. encoder to predict through an encoder. So what we want to do in the first step is to is to provide I mean go through a Gaussian distribution to predict.
The cool buck libeler divergence is just saying how different are these two distribution cool of fee so cool fee and distributed depending on fee of Z given X and P of Z. So these, these expression corresponds to what we call cool buck defamation between two distributions. So, these will be focused during the training in practice I will focus on a sort of reconstruction of the input data. While this part will just make sure that since I passed through the Z, which has a Gaussian distribution then I'm able to get the, the. The last one is a positive term so it means that if I remove it, I'm just getting a lower bound, right. This is something that I can calculate so this is considered as a tractable lower bound of the overall expression that I care about so the probability of X. Okay, so this for the I will train the variation allowed encoder as if it was an out encoder itself. So the training process anyway, with will be obtained by giving something as input and asking the network to provide the same output. The input which is equal to the output which isequal to the input. Why, because it just means that in the middle I was able to capture the all the right distributions. Right. So I'm saying that this thing should be a good estimator for a distribution out of which I will sample Z and then Z will then Z, then X and then sigma. That's what I'm trying to do is make sure is reasonable is that my hypothesis is good.
In an autoencoder, what we have is that for every single x, I have one specific set, and that specific set provides me with the, again, with the x hat. We are learning this distribution, such that then, out of the Gaussian distribution of having the middle I can sample a new instance and generate new data. The structure of this said is such that I'm able then so I can once the model is trained. I forget about the encoder, and I just start from the Z to produce new sample, I can I can instantiate a new set. And these will produce me samples that were not necessarily there in the training set. So, yeah, we'll just keep that. But the interesting thing is that this embedding space that I get in the middle. So anyway, it's a vector, you can think about it as a vector where every element has a specific role. If you train it on faces, and then you look at these component of the Z vector, indeed, they are capturing the pose of the head and the degree of a smile. It's like, I mean, here we're not talking about a language. So there's no language in the. middle we are talking about attributes that are encoded into numbers inside the Z. But you can make a link to the concept of Z. The second element is head pose so the orientation. So I train my network just on this data that I have obtained up the posteriori in the sense that when I go to see what happens inside Z, I realize that it captures some concepts.
The kind of data that we're able to generate through this network were not so good. So the kind ofData that the architecture were able to manage where very small. So again, lower dimensional lower resolution data, and then they were very blurry. So these are new instances generated by rational encoder, but I mean, still, you can say that the model was able to capture the distribution of the data. So, the idea here is that I don't want to deal with complex probability distributions. I suppose they just deal with noise, rather than having said, as we saw before, that was estimated through the encoder and all the machinery of the Gaussian distribution, which is, it's going to be complicated. Start from that, but that is not complicated distribution is just nice. Create me with a network that can bring me from noise to the real. So what can I do is that instead of having the one network, I can combine two parts of the network. So one part is the decoder of the out encoder part. And the other is the generator because it's the real part that is the single sample. So let's say that I have a set of images that describe my real data. And I combine two sets of images to create a new set of data. That's the way in which we can think about all these implicit kind of solution in particular the generative adversarial network. It's not perfect. But this is just summary of what we said.
The discriminator network has to differentiate between the fact that the instance that it is saying is a real image or something that has been produced by the generator. The generator instead want to minimize objective such that these is close to one. And it tells you that it's a very complicated network to to train, because you have to optimize two things that are really going into opposite directions. So there's not just a single loss to focus on a standard network you have lost you look that and you check during the training that this loss goes down. So here you have two things, and it's complicated to to babysit the training courses. And indeed, there is also an issue in the way which we are writing the the objective, because at the beginning. the generator produces something that is crap, right, it's very bad, it produces something not very close to to real images, which means that the life of the discriminator is super easy. So we don't have any, let's say update or helpful information to the discriminators to let it improve. What we've done in the year is just changing the loss a little bit the loss rather than having here minus one. So instead we move it to directly max of D instead of having this kind of concept but the same kind of behavior is the same. This is the discrimator that r, let me see this is the r, that r is r. Okay images. So this is what I'm optimizing with respect to discriminator to be able to separate and to differentiation between real and fake.
The convergence, especially at the beginning quite unstable. So usually you tend to train first the generator a little bit more than the discriminator then you adapt to to. Once you have trained the model, the only part we focus on, then we throw everything else away and we care only about the generator. So, if you provide to this discriminator, something that is an outlier with respect to the data set will tell you fate. In practice, the discriminators you don't necessarily throw it away in all the cases it might be useful for something else. So when you generate. There's no like discriminator so it's discriminator is a classifier. Yes or no, you label it and and just you have quantities like the accuracy that measure how good you were in making a prediction. So with generative models. You're creating something new. What tells you if this new is reasonable or not? So, and this is also the reason why if you think about child GPT there's millions of people that are just evaluating it users they do a lot of user studies. Right. Now, for instance, even for G PT there is this one chart. So the things that it is spitting out there in the chart is this question. Okay, maybe we should ask a human if he likes a new image that the model created to make I mean to evaluate if this is good or not. So one thing that there that one should verify is that the instances that are generated should be different from the training set.
In 2017. If you wanted to go to a conference with a paper, you had to put guns inside your paper. So really 2017 was because the guns came out in 2016. So the year after every conference had at least one part of the, let's say, the aisle of the posters. Session that were completely dedicated to guns. So there were people generating faces to where people generating objects like object centric images. And I mean later in the years to start becoming better and better, even in managing a larger resolution images. So, I have to pass to the next walk of slides. Okay, so. Here, what I wanted to talk now is something which is called doing an adaptation. So taking your what has been produced search for the nearest neighbor and the training set and compare them. So yeah, this is a test that should be done for every model. I might just replicating what I had in the trainingSet or my really creating something. SoYeah, this was done also for the phases. So we have this game theoretic approach like this to competing methods that. so, such that then we are able to sample new instances even if we didn't really tried to define or approximate the density distribution and the probability distribution density function of the data. So this concludes the part on generative models so we said the explicit density model. And so pixel on them and fix the CNN variation of encoder where we have a variation or lower bound and generative internal network where we actually not dealing directly with probability distribution.
The problem is that facing a deployment time a distribution which is very different with respect to the training is not very different but still different from the training. The standard condition is not an exception, because you always have you train something and you deploy it to a user and you don't know exactly how this the user will you will exploit the model. Think about practical application where you have a company that decides to train its own model for the autonomous car to go around, and it trains everything from images in a sunny day lights I mean in daylight. And then, okay, put it in the car, the car goes around during the night and it crashes. But there might be also more complicated cases like snow like fog. So you really have to collect a lot of information to be able to your model to to generalize. There's also an extra, for instance, before we were talking about recognizing the scene and pedestrians, we're talking about detecting objects and again, you should have a model that is able to do it in daylight during night, with regard to regard to pedestrians. Right? So we don't have guarantees on the ability of the model model to make reasonable a good reliable predictions. Right. So how should we manage this? So, if data are extracted from the same distribution. Yes, so you get a very good accuracy. If instead samples are extracted to this different distribution, the accuracy drops a lot. Right, so yes, if the model is a foundation model is super huge.
In theory, if I train a model one of these data set that should be able to recognize the same concept in another data set, they were all supposed to be instances of the real world. So there is a domain shift, right. So you have to do two things on one side, you get this effect of being cheaper, because you're using data that are cheaper. But then you have the fact that you have a domainShift. Now this issue of how to face the domain shift and how to close the domainShift has been, let's say brought to the table. Some years ago, it took about 2011, where people started realizing that every sub community inside the computer vision, let’s say community, everyone every every sub problem. They were creating every sub areas, there was a specific data set. Then they started doing their own experiments to demonstrate that if you train on one data set you were getting very bad results on other data sets. And they were competing it with anotherData set like Caltech. So the concept in Caltech if you look at what is a car is just a back and white cars all are in the same way. And instead, if you are inside image that is that car they are r       ss of the lighting condition, regardless of flashes that can happen. And besides that, let't suppose you have model that has been trained on RGB images. So now you're on the car you have all to other sensors like that information, right?
 domain adaptation problem is related to the fact that apparently I'm trying to solve the same task from two different domains a source domain and a target domain. The, the task is the same because, for instance, I want to recognize car. It should be car in the source and the target, but the domain from which the data were extracted are different. So the, the source domain adaptation setting is usually defined as a transductive setting, which means that you know the data, the testData, the target data are available at training time. So this is the way to simplify the problem right because there are two and we'll discuss about later on. There are two levels, either you adopt or you generalize. So we tend to use. the first level, you really have one to have a model that whatever it will see a test time it will be good enough and provide good prediction. Adopt instead, so this is generalized. We don't have a generalization we don't want to generalize, we just want to know what is the target on my adaptation. So it means that I want, I will access the data. This will be my test data, but I see them during training. This is a typical transductives setting. So then there are many sub cases or variants of the, let's say of the structure of the problem, you can have just one single domain and the source. You can have mixed sources in the sense that here, you know, this is paintings,. this is photos, this are sketches. So there might be different settings they can also have.
In generalization, since you want to generalize you expect to have multiple sources so you don't have just one source domain, you have many of them. So what I would like to do is to have a condition in which I project my data into another space where instead two domains are overlapping. So if I'm able to do that then once I've trained a model on the blue data it works, it will work well also on the red ones. So this logic was adopted through this first let's say method that is applying maximum mean discrepancy. But there has been other strategies in the years, but let's let me go there. That's still the most effective approach today if you have today to think about the main rotation that I would suggest everybody to use is this one. Okay, so  th  think about these two domains. So  so    so the target data. I don’t have labels, but what I can do is ask that the representation of my target data gets close to representation of the source data. Right so it's this concept of maximum in discrepancy. Inside the deep network. There has been some some variants of this joint maximum. in discrepancy where all this information where first and then compared between source and target. But   the main one is the one that I think about now, is this two domains that we can use now. If we're able we get back. So, this is continuous day. Well, since we don't has, I mean, a lot of time, and the next exercise will be on one of these domain adaptation approaches.
In theory, if they live in two different part of the, let's say embedding space, it means that I can always have a simple linear classifier that separate them. But once I push the two distribution one over the other, then my binary distribution my binary classifier will be so the logic can be let's try to exploit this. So, if I instead, I'm able to do something such that the two. distribution get close together like what I was doing with maximum in discrepancy like so trying to push. the two domains to be close. And then at this point, my binary. classifier is not able to work anymore. But then these is doing the opposite of what I want, right because this is trying to separate. Right so here if they are far apart my line is perfectly good in separating them. So I want what I'm trying to do is to find the representation that, at the same time, brings me to a model that is able to correctly classify the source and let the two domain overlap. And that's the reason why I have a reversal gradient here. So we have a part here that is just extracting the feature a part of. the network that is working as a classifier for the labels of the object and the part. of thenetwork that is instead running domain classification source from target and I invert the gradient. So this will be the model that you will exercise on in the next week. So if you want to look at the equation right so if you look going to the paper. First publication was an ICML in 2015 presented this work.
The model is able to reconstruct both the source and the target data. It's able to produce reasonable and reasonably good labels also for the target set, although there were cartoons and they were very different visually with respect to the to the photos or the other domain. So this was a type of let's say mistake in the original paper. So if you read the maths, you can try to understand what's happening, and you also realize that sometimes there are errors. So even this can be a sort of, I mean, it means that during while I'm training the source model, I'm able to find a space where both source and target are projected such that there's just the representation of the two data. Still you have a multitask problem I would say so next time I mean next week we have the exercise and then we start again with a presentation. So, this is just a way to encourage you to read. Well, the details of the papers first because in the last there's always explanation of what a model is doing. And it's even because if you find that there is a mistake or event, this was just a typo, but there might be some logic mistake that then can be the beginning of your paper next time. Right. Okay, so then the effect of the model is that we start from something of this kind. And this is elaborated and the g of D with a set of parameter t that the output of this is compared with mistake. Right?
The total operation is completed in: 11 minutes and 31.85 seconds
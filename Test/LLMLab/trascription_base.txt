년 www.yeh.exe Дай Многоhmm lever assign me programming. Аormuşка Эр küçидpering На Вы уже знаете, что теперь мы с ним ходим на другое деление. Спасибо, пожалуйста. Реоприographical osoб herkes Barker подтверд Ira Pr향 znал реакдации на нов 그런 corporate feature. Редактор субтитров А.Семкин Корректор А.Егорова Редактор субтитров А.Егорова Редактор субтитров А.Егорова Кажем, подvoc 팔ars, я согласен тебя utilityorem neue и серов aquell seine hepsак не pimuba и такси, не вGB was also in your shortlist of possible selected ones. Я mean, these stuff here was actually already paper, so it was a reporter of something that was completely done, I mean, at least in a very preliminary way, okay. So we have the background and Здесь THIS environment made out of Bose, Issha. Это une problапная wygląda или, по correspondению кiresк guidance, или, якобы, есть несколько ф platforms insanely boosted in the local software, и соication blockchain itself is the development of secure overarching blockchain products. special way, which it is not like defining requirements like user stories, but with a kind of different format. So instead of defining a user stories directly, I define goals for each user, and then kind of sub goals. So you will see that you have several phases that are defined by these goal oriented requirements engineering Bros. я понимаю, не инвоним на barn. Тут не ин Kwangили три миниферента фейсесс, голмоделинга, я снижу, что вы думаете, что вы думаете о моем гольце. Я have a goal specification, so precise specification of goals to support, then later the requirements, and finally goal reasoning. So elaboration of the goal by verifying that they correspond with the requirements of the system, validating the goals, by identifying scenarios covered by them and operationalizing the goals. What does it mean in practice? So, I mean, this is still a super abstract, but as you have in the description of the stuff, you have three different parts. The first one goes does goal modeling, the second one does goal reasoning, and the third one does operationalization of the goals. By means of extracting high level goals, so the main ideas, extracting low level goals, so the more detailed, the fine grain goals, and then API script generation. So in addition to having just the low level goals, I also pick a swagger file with the APIs, and I assign each low level goal to an API. Okay, good. Meaning that we have something like this for each user. I get the goals, I get the low level goals, and then I get the map finger to the API endpoints. Okay, what was done in this preliminary research? Some things around, but at the very end, what you have here is that everything was made with GPD4. So this was a super simple kind of experimentation that was made manually by using the GPD. Of course, you can transform this, you have to in the project, with an infrastructure with some agentic modules made by calls to JAMA or any other kind of LLM system. But anyway, you see here that you have, it is basically the prompt engineering is the script, it is the scribe here. So three different steps, three different prompts, and whatever. In this case, I want to just describe the actors. In this case, I want to pick the high level goals here, no, this one is for the low level goals, this one is for the high level goals, so high level goals, low level goals, and then here there is mapping between the API endpoints and low level goals. You actually see that you have a structure of a chain of different prompts, where each input is provided, there's each output is provided, there's part of the input of another prompt. In fact, you see here, results of prompt two, results of prompt three. What was the analysis carried here? I mean, you cannot visualize nothing here, but actually you have a high level goal and a numbering, high level goal name, low level goal description, so actually what I got from my, from my second module of the architecture, and then finally the mapping with the endpoints. That of course here you don't see anything, but here I have actual mapping to an endpoint, like slash contributors, slash statistics, slash projects, and here you see not applicable with the current sector APIs. You remember that we said that when we have applications to software engineering practices, my metrics at the very end will not be generic, like I am not making a training, or I am not building an LLM, so I don't have to provide my Rouge, Blow, and whatever. The only thing that I have to do is to define a specific metrics that are okay with my current, my current, let's say experiment that I am doing. In this case my metric was finding how many of the real APIs I was able to cover, okay? So let's suppose that here I have 20 APIs, I do these I level, low level, and then API might think, and then I find out that I covered just two APIs out of 20. It means that my goals are useless because I am not mapping them to real APIs. If I say I'm not like 18 APIs out of 20, it means that it is better functioning and so I can trust this stuff to create kind of best cases or end-to-end best cases for API executions. So actually this is actually everything that you have to perform. In this example here, when if we take our text, you have the full description of what you have to do like here, this one. Okay. Let's move on to the bottom here in the middle. Okay. So you have the case study that we want to use, which is this one. In this case, it is a EvoMaster benchmark. And in this EvoMaster benchmark, you have the, you have in some places that I actually don't remember, but somewhere, somewhere here you have a folder where you have all the APIs. Okay, like this one. You have this Wager files of all the APIs. And then, so this is my APIs folder. The ones that I want to map with my goals. But where do I extract the goals? There is somewhere a list of all the projects in this repo, which is maybe in the read me. I don't know. Nope. Okay. Yeah. You have here the links from the GitHub projects related to the APIs. So I have the GitHub projects plus the APIs. I take the GitHub project. I find a project with a description like this. I look at something in the description and I find the goals from the description. This is actually what was known and it is documented. So I take the description of the project, I take the goals, I take the low level goals and then I try to map them with the APIs. So this is the exercise. As I said to someone, because last time you asked me, how much time do I need for doing this stuff? I have to be super honest in this experiment here, which I mean, I feel bad even in calling it an experiment. This actually was done in an afternoon, because it was like, okay, we set up this idea and we just start to type some random stuff into GPD and get the results. Okay, so don't be afraid about the fact that you may need some setup and some setting up because the actual application, if you're lucky enough like your prompts work out of the box and you don't have some issues with the setup, you may be able to make everything in a couple of days, just to describe the results. And at the very end, you see that if I mean, if you want to use a GPT, but actually it is better to try to create some infrastructure by yourself, you see that actually documenting your results will have to follow what structure the similar to this one. I provided all the information about the prompt engineering that I did. If I did an architecture, I write down the architecture and actually it is this one. So the architecture is here, it is super simple, but it is actually defined there. Bonus, I mean, Bonus points for credibility, you mentioned what type of architecture it is. So this is an agentic chain like we have said last time. This is a chain of agents with three agents and blah, blah, blah. According to the cognitive architecture, the finishes that we provided last time. So nothing more than this actually. And at least for the application, which I am dealing with, as promised, I will provide you additional information for each one of them. Because I know that some of them can see a little bit scary, especially when I talk about testing Android applications. Because there you need two additional layers. You need to have an Android application environment running plus you need to create some test cases for them. But I will add some additional information. So don't be afraid about that. Everything will be guided. And I will provide also the other ones. I will share the skeleton of the whole projects by the end of tomorrow. You will have this additional guidance for doing this. I will also share this PDF for guidance. Yes. In this case, you don't have an agentic architecture. If you are not necessarily, I mean, you don't... No, no, no, no, no. This is just linear chain of LLM prompts. Okay. I mean, you have to describe your architecture. We don't have any expectation about having a full agentic architecture or whatever. You may also have... You may have a loop, for instance, going back. And you know how to call that loop, that loop. Because every time you have a loop in an architecture, you are talking about reasoning, self-critic. Right? So it is just another problem. I use some stuff. I use the right names for what I am doing. Do I have an LLM prompt selecting what I have to do? That will be a router. We say that. And we will make another example with a router in the next lab. Okay. But anyway, there are so many possibilities in combining this stuff together that actually, even if you are at the simplest, I mean, among the simplest alternatives, you have things to say. I decided to chain this stuff. I made this prompts. So what are the prompt engineering techniques that I applied for creating these prompts? And I start saying all of them. I have the priming because I am putting the context over there. There are examples, no examples. So this is one short, zero short, sorry. I don't know, but there is nothing else interesting here. Actually, this one with GPT4 worked like a champ, because I mean, GPT4 is always a lot more powerful, I mean, more seemingly precise out of the box than LLM. I expect that if I did that with LLM without providing any prompt examples, this will have been completely unusable, the result. I exactly expected to be like that. But anyway, it depends, I don't know. I didn't try it. So you can try this and this will be one of the alternatives. Okay. So my promise is that before the end of tomorrow afternoon, I will open a crest. Nice. I will provide you the full descriptions and the steps for all the different projects, application projects that are provided. Okay. I see that in the project location sheet, you have already 11 groups defined with 18, 2022, 25, 26 people. Okay. I don't know how many people I expect to be there, because I mean, we have 60 people enrolled, I mean, being an optional course, plus having a lot of different, complex questions in the beginning. I know that maybe someone changed this line, but yes, remember that you have to feel that sheet at least with the project members. So, I mean, if you don't have the preferences or the 30 of the member, which is next, next, next, how do they, I mean, I don't care. So, Mark, we can also fill them later next week. But please, feel at least the people for the group, for the group composition, because I don't want, and we don't want to come after you to ask you, you didn't put your name there, you won't be able to get the mark for this grade. I mean, there's a deadline, please, please be in that deadline. Okay. And I am also creating another, let's say, this is not very good for privacy, but whatever. But I mean, you don't even see anything there, so it's perfect for privacy. That's why we have this perfect resolution in these devices. I am creating another column here, which is people needing a group. So, just, right, eventually, your name, surname, and email there. So, if you need to connect with each other to form a group, you can use this column. And next Monday, when the groups formation are closed, I will make a pass on this in class and facilitate some group creation for someone who didn't make it for the group. Okay. So, as promised, I have now a, you can have some time on Lab7. Lab7 has been updated a couple of times, because I recognize that I have updated the resolution in the beginning. But anyway, now it is the right one. So, again, we have already seen this, and we want an agent, an agent, an architecture, whatever it is, and it is actually this one. So, you have more details later. For the creation of user stories, I actually do have a ground truth in this case. So, last time, we have said that every time I have a ground truth, every time I have something, I can compare with, I can compute my precision recall by comparing my results, my actual results, we call them actual results, with the expected results. That is my ground truth, or something in my ground truth. So, this will be super simplified at the moment, because we are considering exact similarities, we will get there in a while. So, there is a, when we have, when we want to compute, actually, the precision recall, we have to cope with the fact that something must be exactly the same with the same works, and characters to be corresponding, right? So, if I have a user story in my ground truth, which is, I want to see a list of places, and my result is, I want places listed. Of course, this is the same. So, having a one-to-one string of comparison between my actual and expected result is not optimal, of course. To solve this stuff, we will see that we apply cos I'm similarity again. It is kind of our jolly move when we have to compare something. But, in that case, we have to, if we want to automatize it, we have to apply a threshold for similarity. I will say, this is this, if my cos I'm similarity is above a certain threshold. Of course, this threshold is crucial for my results, because I can say that the threshold is 95%, and I don't find anything, because maybe I don't have any similarity such high. Or maybe I can say that my threshold is 10%, and then everything starts to respond to everything else. So, that's a disaster. We will see that in this case, and we will make a full example next time. Typically, we resort on changing the threshold and looking at the asset of a different threshold and computing what is called an ROC curve. And we see how we change our precision, and we call according to the threshold that we are using. So, the bonus point here is that we actually see that applied the two stories, I mean, generation, which is something more. But anyway, without going into that part that we see next time, in this case, we have just three modules. The first one extracts the roles from my requirements. So, I feed my whole requirements with some context to these engines. And this guy here, we left to extract my roles, at least of the roles with that my system. Then I have another prompt, this one, the function extraction. This is not evident from here, but this is actually, I actually have an iteration here, because I, for each role, I extract his functions. So, I have, let's say, four roles. I will call this module here for different times, one per each role. At the end of this, I get my functions. So, remember the structure of a story as a role. I want to function. At the end of this, I have a set of, I mean, a list of lists, because I have a list of roles, and each role has a list of functions. The last one is the, let's say, the most simple one, because it is the parko's extraction. The parko's extraction is the parko where I say, I want to, blah, blah. In this case, what I give there, I give, a role, a function, and the requirements. So, you actually see one thing immediately here. Let's suppose that I have four roles. So, first prompt, I execute it a single time, and I get four roles. The second prompt, I have to execute it four times, because I want the functions for each role. The third prompt, unless I perform some optimization and try to make multiple things together in the same prompt, I have to call it, in this case, 60 times, because I have four roles, times 15 functions. So, ideally, this parko's extraction prompt, I call it 60 times, and you know how this can become a tragedy in our systems if I don't have a GPU, or in color, if I am using the three one. We will see in the text later that we simplify this. So, we don't get to the real software, but we make this way more simple, let's say. Let's look a little bit at the text. So, we have our requirements here. This is taken from a software engineering tool, edition of the course. I don't know. Now, some of you was enrolled in software engineering tool, but this is not our current project. This was like from 2022, I don't know. But it is a hiking platform. So, it is a platform where I have these guys that can check the trails and organize some hiking. So, whatever, text. Here, I put some helper function, our climate, and we pass just three parameters, the prompt, the max length and the temperature, the exit. You will have to customize the max length, of course. Blah blah blah. The typical capital of friend stuff. And then, first part, extracting the actors. So, I want the LLM to extract the actors here. The exercise is guided. So, here, I created three different, I mean, placeholders for three alternatives for this prompt. So, I want to see what happens if I give a context with zero shot, a context with one shot, and a context with few shots. What will be a one shot or few shot prompt here, example? It will be a piece of requirement, and the actors from that piece of requirements. So, you don't have anything here. My suggestion is that either you go on some repo, from software engineering to or whatever, you find some requirements in the web, and you find the actors here, self, or easier. You ask GPD for, to create some examples. I mean, it works. I ask GPD for, write me a paragraph of requirements based on these actors here. So, you say it, and you say, I want a system for managing a university with students, professors, and blah blah. And you ask GPD to make the requirements. You get the requirements, so you have a paragraph of requirements with the actors below. So, you can be creative there. You can also write them yourself, but it's not in the task. So, in general, we have three prompts, and then we try, what happens with all of them. There is a bit of, I mean, configuration here, and at the very end, I have to find the extracted roles. So, here, to find the extracted roles, I will need some textual editing of the result, right? Because I get all that bullshit with the prompt inside the prompt, I need to get rid of the prompt and format the results. So, I get to the second part, and this is actually where we compute the precision of the call. So, always the same definitions from precision recall. And what I have to do here is create a function to extract the roles from my user stories. The user stories are here. So, here I am a user source, and this is my set of user stories. It is actually in the column description. Here, I just need some Python code to open this USB, get this, and play it so that I remove this, I remove this, and I get it. So, nothing shocking. I just have to extract a piece of text from a format to the same. Nice. So, this function here must give me the roles from the stories, where I am here. So, you pass a file and you extract them. Then, okay, so find the unique roles and put them into a list so that they get the expected results for the roles. Actual roles. So, actual roles will be my list taken from the prompt. It will be my actual result for roles. So, at this point, I get my expected results and my actual results. Here, once I actually see, I can compute my positives through positives, positive, positive, positive, positive, positive, positive, positive, precision, and recall. Just by comparing the strings, what, the strings, why, one after the other. This is important here. Use normalized roles. I mean, don't consider spaces, the S at the end, capital and non-capital lettering. We are comparing strings like they are, but I mean, we use some intelligence in that we don't consider the capitalization, the spaces, so we trim the strings and whatever. And so, actually, at this point, we have for the first module the whole execution and validation of precision and recall. I mean, this is a full exercise, let's say, because it requires time to arrive there. But, let's say, as bonus, we have a second part, which is extracting the function. And so, what I do is we have here. We have to define a prompt. Look over the list of roles and extract the piece of text from requirements related to the role. So, I want to prompt to extract functions for a given user. The prompt will be composed of the following fields, context, examples, task, and answer field. And exit. So, basically, I, this prompt, here, I put some examples by my own, but the result will be that I get, I feed these, my requirements, my role, and I ask you to find the function for this guide here. My result at the end will be a set of different functions. I also created here an extract functions to, that I have to define, to get the list of functions from the response, I'm formatted. And then I created a super simple function that creates the user stories once I have the role and the list of functions. So, this is already made. You don't have to do anything with it. Because I get the, as a role, I want to function. I mean, it is also formatted as a tuple. So, actually, it creates tuples with role function, role function. So, role, user story, let's say. But I mean, this is just for, for, for mapping them. So, at the end of this, I get a set of tuples with role and a function associated with the role. Here, I called, I called also, validate the precision recall by using some thresholds and whatever. I don't do it. So, the only thing that I do here is, I create them and I look at them. Okay? At the end, the last thing will be extracting the purposes. So, as we said in the diagram, I feed the tuple to a new prompt, the role and the function. And I see what is the purpose. So, they saw that I. So, ideally, here, we take the pairs role function, obtaining the previous step. But you see here, for simplicity, we only consider two user stories at this point. And there is a new simple, because otherwise, I will have to do, like, six years' execution of the prompts. So, you see, to complete the task, we would require to perform an iteration of all the stories defined. This will be a computational expense, and it is out of the scope of these, so on. So, actually, at the end, I need to make some prompt engineering for this, and I do this only for two stories. Okay? So, I mean, let's consider this two as a kind of bonus. It is important to arrive at least here. So, I have very precise task extractor roles, and they also have an A-nec, and it is for computing precision, I recall. And I mean, this is, I can consider it feasible. I mean, we have, like, 35 minutes from now, but you can start doing that, and on Monday, we can see together the code, and have some examples of that. And then, on the rest, we can build upon with the computation of some thresholds and whatever. Okay. So, if you have no questions, I will close the, the next problem here. So, you have until 5 to 13, to work on that. And that's it. Okay.
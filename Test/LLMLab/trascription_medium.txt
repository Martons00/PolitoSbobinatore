 Så är det inte bara ljud och pråk med Veighett utav Det kan vara Ska vi se om audio ska fungera? Låt mig veta. Okej, så den här gången har vi mikrofonen. De flesta videorna fungerar och det är väldigt underhuvudet. Så, i dagens objektiv, jag ville bara... ...göra en brist introduktion till ett labb som vi har sett förr, i alla fall ett tåget. Och... Jag ville visa er på ett par gånger några ytterligare... ...detaljer om några applikationprojekt. Så, nu ska vi se på den här gärna. Jag kommer att ge er, idag och morgon, några ytterligare... ...exempel. Som en av er frågade, jag tror det var er, ja. För du sa att jag var i klassen och sen gick du och skickade mig en e-mail om det. Och så, det var en av er som gick och sa att jag skulle... ...göra en applikationprojekt. Och så, det var en av er som gick och skickade mig en e-mail om det. Men, detta är ett exempel som är kring API-linkning. Detta kanske var också i din kortlist av möjliga, selekterade. Jag menar, det här var faktiskt redan ett... ...papir. Så det var ett rapport av något som var helt... ...härtat, i alla fall i ett väldigt preliminerat sätt. Så, vi har background och related work här. Detta är något som talas... ...det är förvånligt men du kan i alla fall se några nivåer. Och vi har de olika delar av det här... ...golorienterade behov av ingenjöring. Detta är en del av behov av ingenjöring... ...är definieringen av behov i ett speciellt sätt. Det är inte som att definiera behov som till exempel user stories... ...men med ett lite annat format. Så, använder jag user stories direkt, definierar jag behov... ...för varje användare och sen underbefäst. Så, ni ser att ni har flera fasen... ...som är definierade av denna gola behov av ingenjöringsteknik. Detta är inte inventerad av mig, detta är inte inventerad av de som gör LLM. Detta är nåt som är redan där i software-ingenjöringet. Ni ser här att ni har tre olika fasen. Detta är målmodeller, så jag bestämmer vad som är målmodeller för mitt system. Sen har jag målspecifikationer, specifika målmodeller... ...för att uppfattas på de senaste behovarna. Och senare målreasonering. Så, elaboration av mål, att de skapar med målmodellerna... ...validera målmedel, att identifiera scenarier som är uppkörda... ...för att analysera mål. Vad betyder det i praktik? Detta är fortfarande abstrakt, men som ni har i... ...i beskrivningen av det här... ...har ni tre olika fasen. Den första gör målmodeller. Den andra gör målreasonering. Och den tredje gör målmodeller. Med betydning av att uppfattas med hög- och nivånivånivån... ...så de mer detaljade, fingränta mål... ...och sen API-skrifter generation. I addition to having just the low-level goals... ...I also pick a swagger file with the APIs... ...and I assign each low-level goal to an API. Meaning that we have something like this for each user. I get the goals, I get the low-level goals... ...and then I get the mapping to the API endpoints. What was done in this preliminary research? Some things around, but at the very end what you have here... ...is that everything was made with GPT-4. This was a super simple kind of experimentation... ...that was made manually by using GPT. Of course you can transform this, you have to in the project... ...an infrastructure with some agentic modules... ...made by calls to JAMA or any other kind of LLM system. But anyway, you see here that you have... ...basically the prompt engineering is described here. Three different steps, three different prompts. And whatever. In this case I want to just describe the actors. In this case I want to pick the high-level goals. Here, this one is for the low-level goals... ...this one is for the high-level goals. So high-level goals, low-level goals... ...and then here there is mapping between the API endpoints and low-level goals. You actually see that you have a structure of a chain of different prompts... ...where each input is provided as part of the input of another prompt. And in fact you see here results of prompt 2, results of prompt 3. What was the analysis carried here? I mean, you cannot visualize nothing here... ...but actually you have high-level goals and a numbering. High-level goal name, low-level goal description. So actually what I got from my second module of the architecture. And then finally the mapping with the endpoints. Of course here you don't see anything, but here I have actual mapping to an endpoint... ...like slash contributors, slash statistics, slash projects. And here you see not applicable with the current set of APIs. You remember that we said that when we have applications to software engineering practices... ...my metrics at the very end will not be generic. Like I am not making a training or I am not building an LLM... ...so I don't have to provide my Rouge, Blau and whatever. The only thing that I have to do is to define a specific metrics that are okay... ...with my current experiment that I am doing. In this case my metric was finding how many of the real APIs I was able to cover. So let's suppose that here I have 20 APIs. I do this high-level, low-level and then API mapping... ...and then I find out that I covered just two APIs out of 20. It means that my goals are useless because I am not mapping them to real APIs. If I say that I map like 18 APIs out of 20... ...it means that it is better functioning and so I can trust this stuff to create... ...kind of test cases or end-to-end test cases for API executions. So actually this is actually everything that you have to perform. In this example here, if we take our text, you have the full description of what you have to do. Like here. This one. The zoom panel doesn't stay in the middle. So you have the case study that we want to use, which is this one. In this case it is an EVO master benchmark. And in this EVO master benchmark you have the... ...you have in some places that I actually don't remember but somewhere... ...somewhere here you have a folder where you have all the APIs. Okay, like this one. You have the swagger files of all the APIs. And then, so this is my APIs swagger. The ones that I want to map with my goals. But where do I extract the goals? To extract the goals there is somewhere a list of all the projects in this repo. Which is maybe in the readme. I don't know. Nope. Okay. Yeah. You have here the links from the GitHub projects related to the APIs. So I have the GitHub projects plus the APIs. I take the GitHub project. I find a project with a description like this. I look at something in the description and I find the goals from the description. This is actually what was done and it is documented. So I take the description of the project, I take the goals, I take the low level goals and then I try to map them with the APIs. So this is the exercise. As I said to some one of you, because last time you asked me how much time do I need for doing this stuff, right? I have to be super honest in this. This experiment here, which I mean I feel bad even in calling it an experiment. This actually was done in an afternoon because it was like, okay, we set up this idea and we just start to type some random stuff into GPT and get the results. So don't be afraid about the fact that you may need some setup and some setting. Because the actual application, if you are lucky enough, like your prompts work out of the box and you don't have some issues with the setup, you may be able to make everything in a couple of days just to describe the architecture and describe the results. And at the very end you see that if you want to use a GPT, but actually it is better to try to create some infrastructure by yourself, you see that actually documenting your results will have to follow a structure similar to this one. So I provide all the information about the prompt engineering that I did. If I did an architecture, I write down the architecture. And actually it is this one. So the architecture is here. It is super simple, but it is actually defined there. Bonus, I mean bonus points for credibility. You mentioned what type of architecture it is. So this is an agentic chain like we have said last time. This is a chain of agents with three agents and blah, blah, blah. According to the cognitive architecture. Definitions that we provided last time. So nothing more than this actually. And at least for the application which I am dealing with, as promised, I will provide you additional information for each one of them. Because I know that some of them can seem a little bit scary, especially when I talk about testing Android applications. Because there you need two additional layers. You need to have an Android application environment running. Plus you need to create some test cases for them. But I will add some additional information. So don't be afraid about that. Everything will be guided. And I will provide also the other ones. I will share the skeleton of the whole project by the end of tomorrow. You will have these additional guidance for doing this. I will also share this PDF for guidance. Yes. In this case you don't have an agentic architecture. No, no, no, no. This is just a linear chain of LLM prompts. I mean you have to describe your architecture. We don't have any expectation about having a full agentic architecture or whatever. You may also have a loop for instance going back. And you know how to call that loop. Because every time you have a loop in an architecture, any architecture, you are talking about reasoning and self-critic. So it is just a matter of I use some stuff. I use the right names for what I am doing. Do I have an LLM prompt selecting what I have to do? That will be a router. We say that. And we will make another example with a router in the next lab. There are so many possibilities in combining this stuff together that actually even if you are among the simplest alternatives, you have things to say. I decided to chain this stuff. I made these prompts. So what are the prompt engineers? I made these prompts. I made these prompts. I made these prompts. I made these prompts. I made these prompts. I made these prompts. So what are the prompt engineering techniques that I applied for creating these prompts? And I start saying all of them. I have the priming because I am putting the context over there. There are examples. No examples. So this is a one shot, zero shot, sorry. I don't know. There is nothing else interesting here. Actually this one with GPT-4 worked like a champ. Because I mean GPT-4 is always a lot more powerful. I mean more seemingly precise out of the box than LAMA. I expect that if I did that with LAMA without providing any prompt examples, this would have been completely unusable, the result. I exactly expect it to be like that. But anyway, it depends. I don't know. I didn't try. So you can try this and this will be one of the alternatives. Okay. So my promise is that before the end of tomorrow afternoon I will... Opera crashed. Nice. I will provide you the full descriptions and the steps for all the different projects, application projects that are provided. Okay. I see that in the project allocation sheet you have already 11 groups defined with 18, 20, 22, 25, 26 people. I don't know how many people I expect to be there. I mean we have near 60 people enrolled. But I mean being an optional course plus having a lot of different complex questions in the beginning. I know that maybe someone changed his mind. But yes, remember that you have to fill that sheet at least with the project members. I mean if you don't have the preferences for the 30th of November, which is next Saturday, I mean I don't care so much. We can also fill them later next week. But please fill at least the people for the group composition. Because I don't want and we don't want to come after you to ask you. You didn't put your name there. You won't be able to get a mark for this grade. I mean there's a deadline. Please be in that deadline. Okay. And I am also creating another, let's say this is not very good for privacy, but whatever. But I mean you don't even see anything there. So it's perfect for privacy. That's why we have this perfect resolution in these devices. I am creating another folder, another column here, which is people needing a group. So just write eventually your name, surname and email there. So if you need to connect with each other to form a group, you can use this column. And next Monday when the group's formation are closed, I will make a pass on this in class and facilitate some group creation for someone who didn't make it to the group. Okay. So as promised, I have now a, you can have some time on lab 7. Lab 7 has been updated a couple of times because I recognize that I have updated the solution in the beginning. But anyway, now it is the right one. So again, we have already seen this and we want another agent architecture or whatever it is. And it is actually this one. So if you have more details later for the creation of user stories. I actually do have a ground truth in this case. Last time we have said that every time I have a ground truth, every time I have something I can compare with, I can compute my precision and recall by comparing my results, my actual results. We call them actual results with the expected results. That is my ground truth or something in my ground truth. So this will be super simplified at the moment because we are considering exact similarities. We will get there in a while. So there is, when we want to compute actually the precision and recall, we have to cope with the fact that something mustn't be exactly the same with the same words and characters to be corresponding. If I have a user story in my ground truth, which is I want to see a list of places and my result is I want places listed, of course this is the same. So having a one to one string comparison between my actual and expected result is not optimal of course. To solve this stuff we will see that we apply cosine similarity again. It is kind of our jolly move when we have to compare something. But in that case we have to, if we want to automatize it, we have to apply a threshold for similarity. I will say this is this if my cosine similarity is above a certain threshold. Of course this threshold is crucial for my results because I can say that the threshold is 95% and I don't find anything because maybe I don't have any similarity such high. Or maybe I can say that my threshold is 10% and then everything starts to correspond to everything else. So that's a disaster. We will see that in these cases and we will make a full example next time. Typically we resort on changing the threshold and looking at a set of different thresholds and computing what is called an ROC curve. And we see how we change our precision every call according to the threshold that we are using. The bonus point here is that we actually see that applied to storage generation which is something more. But anyway without going into that part that we will see next time, in this case we have just three modules. The first one extract the roles from my requirements. So I feed my whole requirements with some contacts to this engine. And this guy here will have to extract my roles, a list of the roles with my system. Then I have another prompt, this one, the function extraction. This is not evident from here but this is actually, I actually have an iteration here. Because for each role I extract his functions. So I have let's say four roles. I will call this module here four different times, one per each role. At the end of this I get my functions. So remember the structure of a story as a role I want to function. At the end of this I have a set of, I mean a list of this because I have a list of roles and each role has a list of functions. The last one is the, let's say the most simple one because it is the purpose extraction. The purpose extraction is the part where I say I want to blah blah. In this case what I give there, I give a role, a function and the requirements. So you actually see one thing immediately here. Let's suppose that I have four roles. So first prompt I execute it a single time and I get four roles. The second prompt I have to execute it four times because I want the functions for each role. The third prompt, unless I perform some optimization and try to make multiple things together in the same prompt, I have to call it in this case 60 times because I have four roles times 15 functions. So ideally this purpose extraction prompt I call it 60 times and you know how this can become a tragedy in our systems if I don't have a GPU or in Colab if I am using the free one. We will see in the text later that we simplify this so we don't get to the real stuff but we make this way more simple. Let's look a little bit at the text. So we have our requirements here. This is taken from a Software Engineering 2 edition of the course. I don't know. Some of you was enrolled in Software Engineering 2 but this is not our current project. This was like from 2022. I don't know. But it is a hiking platform. So it is a platform where I have these guys that can check the trails and organize some hiking. Okay. So whatever. Here I put some helper function, ask llama and we pass just three parameters, the prompt, the max length and the temperature. That's it. You will have to customize the max length of course. Blah blah blah. The typical capital of French stuff. And then first part extracting the actors. So I want the actors to be the same size as the actual ones. So I need the LLM to extract the actors here. The exercise is guided. So here I created three different placeholders for three alternatives for this prompt. So I wanted to see what happens if I give a context with zero shots, a context with one shot and a context with few shots. What will be a one shot or few shot prompt here? It will be a piece of requirement and the actors from that piece of requirements. So you don't have anything here. My suggestion is that either you go from software engineering to whatever. You find some requirements in the web and you find the actors yourself or easier. You ask GPT for to create some examples. It works. I asked GPT for write me a paragraph of requirements based on these actors here. You say it and you say I want a system for managing a university with the students, professors and blah blah. And you ask GPT to make the requirements. You get the requirements so you have a paragraph of requirements with the actors below. So you can be creative there. You can also write them yourself, but it's not the task. So in general we have three prompts and then we try what happens with all of them. There is a bit of I mean configuration here and at the very end. I have to find the extracted roles. So here to find the extracted roles. I will need some textual editing of the result, right? Because I get all that bullshit with the prompt inside from Lama. I need to get rid of the prompt and format the results. So I get to the second part and this is actually where we compute the precision and recall. So always the same definition for precision and recall. And what I have to do here is create a function to extract the roles from my user stories. The user stories are here. So here I am my user stories. And this is my set of user stories. It is actually in the column description. Here I just need some Python code to open this CSV. Get this and split it so that I remove this and I get high-tech. Nothing shocking. I just have to extract a piece of text from a formatted string. Nice. So this function here must give me the roles from the stories. Where I am here. So you pass a file and you extract them. Then, okay, so find the unique roles and put them into a list so that they get the expected results for the roles. Actual roles. So actual roles will be my list taken from the prompt. It will be my actual result for roles. So at this point I get my expected results and my actual results. And then here, once I have two lists, I can compute my positives, true positives, false positives, false negatives, precision and recall. Just by comparing the strings one after the other. This is important here. Use normalized roles. I mean, don't consider spaces. So we are comparing strings like they are, but we use some intelligence in that we don't consider the capitalization, the spaces, so we trim the strings and whatever. So actually at this point we have for the first module the whole execution and validation of precision and recall. This is a full exercise. But let's say as bonus we have a second part which is extracting the function. And so what I do is here. So I have a function. So I have a function. So I have a function. So I have a function. We have to define a prompt. Loop over the list of roles and extract a piece of text from requirements related to the role. So I want a prompt to extract functions for a given user. The prompt will be composed of the following fields, context, examples, task and function field. And that's it. So basically I, this prompt here I put some examples by my own. But the result will be that I get, I feed these my requirements, my role and I ask it find the function for this guy here. My result at the end will be a set of different functions. I also created here an extract functions that I have to define to get the list of functions from the response. I'm formatted. And here I created a super simple function that creates the user stories once I have the role and the list of functions. So this is already made. You don't have to do anything over there. I get the as a role I want to punch. I mean, it is also formatted as a tuple. So actually it creates tuples with role function, role function. So role user story, let's say. But I mean, this is just for formatting them. So at the end of this, I get a set of tuples with role and a function associated with the role. Here I could also validate the precision and recall by using some thresholds and whatever. I don't do it. So the only thing that I do here is I create them and I look at them. At the end, the last thing will be extracting the purposes. So as we said in the diagram, I feed to a new prompt, the role and the function, and I see what is the purpose. So they saw that I. So ideally here we take the pairs, role function obtained in the previous step. But you see here for simplicity, we only consider two user stories at this point. And the reason is simple because otherwise I would have to do like 60 execution of the prompts. So you see, to complete the task, we would require to perform an iteration of all the stories defined. This will be very computationally expensive and it is out of the scope of this. So actually at the end, I needed to make some prompt engineering for this and I do this only for two stories. OK, so I mean, let's consider this too as a kind of bonus. It is important to arrive at least here. I have a very precise task extracted roles and I also have a mechanism for computing precision and recall. And I mean, this is I can consider it feasible. I mean, we have like 35 minutes from now, but you can start doing that. And on Monday we can see together the code and that some examples of that. OK, and then on the rest we can build upon with the computation of some pressures and whatever. OK, so if you have no questions, I will close the room here. You have until five to 13 to work on that.
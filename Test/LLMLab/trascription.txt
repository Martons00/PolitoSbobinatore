 ლლლლ rotary We will go a利 Okay, so this time we have the microphone, those of the video is working, so that's pretty incredible. So objective of today, I just wanted to provide a brief introduction to the lab that we have seen last time.performanceing about some application projects. I will provide you by today and tomorrow some more additional examples. Like someone of you requested, I think it was you, yes, because you told me in class and then you sent me an email about that. But anyway, this is an example related to the one about API linking, which maybe was also in your short list of possible selected ones. I mean, these stuff here was actually already a paper, so it was a report of something that was completely done, I mean, at least in a very preliminary way. So we have the background and related work here, which is something which talks, I mean, it's terrible, but you can at least see some key word. And we have the different parts of these goal oriented requirements engineering. So the main idea of goal oriented requirements engineering is the definition of requirements in a kind of special way, which it is not like defining requirements like user stories, but with a kind of different format. So instead of defining user stories directly, I define goals for each user and then kind of sub goals. So you see that you have several phases that are defined by these goal oriented requirements engineering technique. I mean, this is not invented by me. This is not invented by the people who are doing LLMS. This is something that is already there in software engineering. You see here that you have three different phases, goal modeling. So I decide what are the goals of my system. Then I have a goal specification, so precise specification of goals to support then later the requirements. And finally, goal reasoning. So the elaboration of the goal by verifying that they correspond with the requirements of the system, validating the goals by identifying the scenarios covered by them and the parallelization of the goals. What does it mean in practice? So I mean, this is still super abstract, but as you have in the description of the stuff, you have three different parts. The first one goes does a goal modeling. The second one does a goal reasoning. And the third one does operation, operationalization of the goals. By means of extracting high level goals, so the main ideas, extracting low level goals, so the more detailed, fine grained goals, and then API script generation. So in addition to having just the low level goals, I also pick a swagger file with the APIs and I assign each low level goal to an API. Good. Meaning that we have something like this for each user. I get the goals, I get the low level goals, and then I get the mapping to the API endpoints. What was done in this preliminary research, some things around, but at the very end, what you have here is that everything was made with GPT-4. So this was a super simple kind of experimentation that was made manually by using GPT. Of course, you can transform this, you have to in the project, with an infrastructure with some agentic modules made by calls to JAMA or any other kind of LLM system. But anyway, you see here that you have, it is basically the prompt engineering is described here. So three different sets, three different prompts, and whatever. In this case, I want to just describe the actors. In this case, I want to pick the high level goals here. No, this one is for the low level goals, this one is for the high level goals. So high level goals, low level goals, and then here there is a mapping between the API endpoints and low level goals. You actually see that you have a structure of a chain of different prompts where each output is provided as part of the input of another prompt. And in fact, you see here results of prompt two, results of prompt three. What was the analysis carried here? I mean, you cannot visualize nothing here, but actually you have a high level goal and a numbering, high level goal name, low level goal description. So actually what I got from my second module of the architecture, and then finally the mapping with the endpoints. Of course, here you don't see anything, but here I have actual mapping to an endpoint like slash contributors, slash statistics, slash projects. And here you see not applicable with the current set of APIs. You remember that we say that when we have applications to software engineering practices, my metrics at the very end will not be generic. Like I am not making a training or I am not building an LLM, so I don't have to provide my Rouge, Blau and whatever. The only thing that they have to do is to define a specific metrics that are okay with my current experiment that I am doing. In this case, my metric was finding how many of the real APIs I was able to cover. Okay, so let's suppose that here I have 20 APIs. I do this high level, low level and then API mapping. And then I find out that they covered just two APIs out of 20. It means that my goals are useless because I am not mapping them to real APIs. If I say that I am up like 18 APIs out of 20, it means that it is better functioning and so I can trust this stuff to create kind of best cases or end to end best cases for API executions. So actually this is actually everything that you have to perform. In this example here, when if we take our text, you have the full description of what you have to do like here. The full panel doesn't stay in the middle. So you have the case study that we want to use, which is this one. In this case, it is an evo master benchmark. And in this evo master benchmark, you have the... You have in some places that I actually don't remember, but somewhere... Somewhere here you have a folder where you have all the APIs. Okay, like this one. You have the swagger files of all the APIs. And then... So this is my API swagger. The ones that I want to map with my goals. But where do I extract the goals? To extract the goals, there is somewhere a list of all the projects in this repo, which is maybe in the readme. I don't know. No. Okay. Yeah. You have here the links from of the GitHub projects related to the APIs. So I have the GitHub projects plus the APIs. I take the GitHub project. I find a project with a description like this. I look at something in the description and I find the goals from the description. And this is actually what was done. And it is documented. So I take the description of the project. I take the goals. I take the low level goals and then I try to map them with the APIs. So this is the exercise. As I said to someone of you, because last time you asked me, how much time do I need for doing this stuff? I have to be super honest in this experiment here, which I mean, I feel bad even in calling it an experiment. This actually was done in an afternoon because it was like, okay, we set up this idea and we just start to type some random stuff into GPT and get the results. Okay. So don't be afraid about the fact that you may need some setup and some setting. Because the actual application, if you are lucky enough, like your prompt work out of the box and you don't have some issues with the setup, you may be able to make everything in a couple of days just to describe the architecture and describe the results. And at the very end, you see that if, I mean, if you want to use a GPT, but actually it is better to try to create some infrastructure by yourself, you see that actually documenting your results will have to follow a structure that is similar to this one. So I provided all the information about the prompt engineering that I did. If I did an architecture, I write down the architecture and actually it is this one. So the architecture is here. It is super simple, but it is actually defined there. Bonus, I mean, bonus points for credibility. You mentioned what type of architecture it is. So this is an agent chain, like we have said last time. This is a chain of agents with three agents and blah, blah, blah, according to the cognitive architecture definitions that we provided last time. So nothing more than this actually. And at least for the application which I am dealing with, as promised, I will provide you additional information for each one of them, because I know that some of them can seem a little bit scary, especially when I talk about testing Android applications, because there you need two additional layers. You need to have an Android application environment running, plus you need to create some test stages for them. But I will add some additional information, so don't be afraid about that. Everything will be guided and I will provide also the other ones. I will share the skeleton of the whole project by the end of tomorrow. You will have these additional guidance for doing this. I will also share this PDF for guidance. Yes. In this case, you don't have an agentic architecture. If you are not necessarily, I mean, you don't... No, no, no, no, this is just a linear chain of LLM prompts. I mean, you have to describe your architecture. We don't have any expectation about having a full agentic architecture or whatever. You may also have a loop, for instance, going back, and you know how to call that loop, because every time you have a loop in an architecture, any architecture you are talking about reasoning and self-critique. So it is just a matter of I use some stuff. I use the right names for what I am doing. Do I have an LLM prompt selecting what I have to do? That will be a router. We say that and we will make another example with a router in the next lab. Okay. But anyway, there is... There are so many possibilities in combining this stuff together and actually even if you are at the simplest, I mean, among the simplest alternatives, you have things to say there. I decided to change this stuff. I made these prompts. So what are the prompt engineering techniques that I applied for creating these prompts? And I start saying all of them. I have the priming because I am putting the context over there. There are examples, no examples. This is one shot, zero shot, sorry. I don't know, but there is nothing else interesting here. Actually, this one with GPT-4 worked like a champ because GPT-4 is always a lot more powerful, I mean more seemingly precise out of the box than LLMA. I expect that if I did that with LLMA without providing any prompt examples, this would have been completely unusable the result. I exactly expected it to be like that. But anyway, it depends. I don't know. I didn't try it. You can try this and this will be one of the alternatives. Okay. So my promise is that before the end of tomorrow afternoon, I will open a crash. Nice. I will provide you the full descriptions and the steps for all the different application projects that are provided. Okay. I see that in the project allocation sheet, you have already 11 groups defined with 18, 20, 22, 25, 26 people. Okay. I don't know how many people I expect to be there because I mean we have near 60 people enrolled. Optional course plus having a lot of different complexity questions in the beginning. I know that maybe someone changed this line. But yes, remember that you have to fill that sheet at least with the project members. So I mean if you don't have the preferences for the 30th of November, which is next Saturday, I mean, I don't care so much. We can also fill them later next week. But please fill at least the people for the groups for the groups. Composition because I don't want and we don't want to come after you to ask you. You didn't put your name there. You won't be able to get a mark for this grade. I mean, there's a deadline. Please, please be in that deadline. Okay. And I am also creating another, let's say this is not very good for privacy, but whatever. But I mean, you don't even see anything there. So it's perfect for privacy. That's why we have this perfect resolution in these devices. I am creating another for privacy. So just write eventually your name, surname and email there. So if you need to connect with each other to form a group, you can use this column. So you can use this column. So you can use this column. So you can use this column. So you can use this column. So if you need to connect with each other to form a group, you can use this column. And next Monday when the groups formation are closed, I will make a pass on this in class and facilitate some group creation for someone who didn't make it to the group. Okay. So as promised, I have now a, you can have some time on lab seven. Lab seven has been updated a couple of times because I recognize that I have updated the solution in the beginning. But anyway, now it is the right one. So again, we have already seen this and we want an agent architecture or whatever it is. And it is actually this one. You have more details later for the creation of user stories. I actually do have a ground truth in this case. So last time we have said that every time I have a ground truth, every time I have something I can compare with, I can compute my precision and recall by comparing my results, my actual results. We call them actual results with the expected results. That is my ground truth or something in my ground truth. So this will be super simplified at the moment because we are considering exact similarities that we will get there in a while. So there is a when we have a when we want to compute actually the precision and recall we have to cope with the fact that a something mustn't be exactly the same with the same words and characters to be corresponding. Right. If if I have a user story in my ground which is I want to see a list of places and my result is I want places listed. Of course, this is the same. So having a one to one string comparison between my actual and expected result is not optimal. Of course, to solve this stuff, we will see that we apply co-sign similarity again. It is kind of our jolly move when we have to compare something. But in that case, we have to if we want to automatize it, we have to apply a threshold for similarity. I will say this is this if my co-sign similarity is above a certain threshold. Of course, this threshold is crucial for my results because I can say that the threshold is 95% and I don't find anything because maybe I don't have any similarity such high. Or maybe I can say that my threshold is 10% and then everything starts to correspond to everything else. So that's a disaster. We will see that in this case and we will make a full example next time. Typically, we resort on changing the threshold and looking at a set of different threshold and computing what is called an ROC curve. And we see how we change our precision and we call according to the threshold that we are using. The bonus point here is that we actually see that applied to stories, I mean generation, which is something more. But anyway, without going into that part that we will see next time, in this case, we have just three modules. The first one extract the roles from my requirements. So I feed my whole requirements with some context to this engine. And this guy here will have to extract my roles, a list of the roles with my system. Then I have another prompt, this one, the function extraction. This is not evident from here, but this is actually, I actually have an iteration here because I for each role I extract his functions. So I have, let's say, four roles. I will call this module here four different times, one per each role. Okay. At the end of this, I get my functions. So remember the structure of a story as a role. I want to function. At the end of this, I have a set of, I mean a list of lists because I have a list of roles and each role has a list of functions. The last one is the, let's say the most simple one because it is the purpose extraction. The purpose extraction is the part where I say, I want to blah blah blah. In this case, what I give there, I give a role, a function and the requirements. So you actually see one thing immediately here. Let's suppose that I have four roles. So first prompt, I execute it a single time and I get four roles. The second prompt, I have to execute it four times because I want the functions for each role. The third prompt, unless I perform some optimization and try to make multiple things together in the same prompt, I have to call it in this case 60 times because I have four roles times 15 functions. So ideally this purpose extraction prompt, I call it 60 times and you know how this can become a tragedy in our systems. If I don't have a GPU or in call up if I am using the free one. We will see in the text later that we simplify this so we don't get to the real stuff but we make this way more simple. Let's look a little bit at the text. So we have our requirements here. This is taken from software engineering to addition of the course. Some of you was enrolled in software engineering too but this is not our current project. This was like from 2022, I don't know. But it is a hiking platform. So it is a platform where I have these guys that can check the trails and organize some hiking. So whatever, text. Here I put some helper function, askLama and we pass just three parameters, the prompt, the max length and the temperature, the exit. You will have to customize the max length of course. Blah blah blah, the typical capital of friend stuff. And then first part, extracting the actors. So I want the LLM to extract the actors here. The exercise is guided. So here I created three different, I mean placeholders for three alternatives for this prompt. So I want to see what happens if I give a context with a zero shot, a context with one shot and a context with few shots. What will be a one shot or few shot prompt here example? It will be a piece of requirement and the actors from that piece of requirements. So you don't have anything here. My suggestion is that either you go on some rep or from software engineering or whatever, you find some requirements in the web and you find the actors yourself or easier. You ask GPT4 to create some examples. I mean it works. I ask GPT4 write me a paragraph of requirements based on these actors here. So you say it and you say I want a system for managing a university with the students, professors and blah blah blah. And you ask GPT4 to make the requirements. You get the requirements so you have a paragraph of requirements with the actors below. So you can be creative there. You can also write them yourself but it's not the task. So in general we have three prompts and then we try what happens with all of them. There is a bit of configuration here and at the very end I have to find the extracted roles. So here to find the extracted roles I will need some textual editing of the result. I get all that bullshit with the prompt inside from Lama. I need to get rid of the prompt and format the results. So I get to the second part and this is actually where we compute the precision recall. So always the same definitions of precision recall. And what I have to do here is create a function to extract the roles from my user stories. The user stories are here. So here I am a user stories and this is my set of user stories. It is actually in the column description. So here I just need some Python code to open this CSV, get this and flip it so that I remove this and I get I. So nothing shocking. I just have to extract a piece of text from a format of the string. Nice. So this function here must give me the roles from the stories where I am here. So you pass a file and you extract them. Then okay, so find the unique roles and put them into a list so that they get the expected results for the roles. So actual roles will be my list taken from the prompt. It will be my actual result for those. So at this point I get my expected results and my actual results. And then here, once I have two lists, I can compute my positives through positives, positive, positive, post negatives, precision and recall. Just by comparing the strings one after the other. This is important here. Use normalized roles. I mean, don't consider spaces, the s at the end, capital and non-capital lettering. So we are comparing strings like they are, but I mean we use some intelligence in that we don't consider the capitalization of the spaces. So we trim the strings and whatever. And so actually at this point we have for the first module the whole execution and validation of precision and recall. Okay. I mean this is a full exercise, let's say, because it requires time to arrive there. But let's say as bonus we have a second part which is extracting the function. And so what I do is here. We have to define a prompt. Loop over the list of roles and extract the piece of text from requirements related to the role. So I want a prompt to extract functions for a given user. The prompt will be composed of the following fields, context, examples, tasks and function fields. And that's it. So basically I, this prompt here I put some example by my own. But the result will be that I get, I feed these my requirements, my results, my requirements, my results. And I ask it to find the function for this guy here. My result at the end will be a set of different functions. I also created here an extract functions to that I have to define to get the list of functions from the response, unformatted. And here I created a super simple function that creates the user stories once I have the role and the list of functions. So this is already made. You don't have to do anything with it because I get the as a role I want to function. I mean it is also formatted as a table. So actually it creates tables with role function, role function, role user story, let's say. But I mean this is just for formatting them. So at the end of this I get a set of tables with role and a function associated with the role. Here I could also validate the precision recall by using some thresholds and whatever. I don't do it. The only thing that I do here is I create them and I look at them. At the end the last thing would be extracting the purposes. So as we said in the diagram I feed to a new prompt, the role and the function and I see what is the purpose. So they saw that I. So ideally here we take the pairs role function obtaining the previous step. But you see here for simplicity we only consider two user stories at this point. And the reason is simple because otherwise I would have to do like six years execution of the prompts. So you see to complete the task we would require to perform an iteration of all the stories defined. This will be very computationally expensive and it is out of the scope of this. So actually at the end I need to make some prompt engineering for this and I do this only for two stories. So I mean let's consider this to as a kind of bonus. It is important to arrive at least here. I have a very precise task extracted roles and they also have a mechanism for computing precision and recall. And I mean this is I can consider it feasible. I mean we have like 35 minutes from now but you can start doing that. And on Monday we can see together the code and some examples of that. And then on the rest we can build upon with the computation of some thresholds and whatever. Okay so if you have no questions I will close the the different room here. So you have until five to thirteen to work on that. Okay.
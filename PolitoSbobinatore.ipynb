{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bx5rBfgTUBW"
      },
      "source": [
        "#PolitoSbobinatore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqbQTe4zUFFc"
      },
      "source": [
        "# Insert Your Polito Credentials and Course Information\n",
        "\n",
        "Before running the script, fill in your PoliTo credentials and the course details:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3XRf9ZHOmIM"
      },
      "outputs": [],
      "source": [
        "#INSERT HERE YOUR DATA\n",
        "USERNAME = \"s******\" #POLITO USERNAME\n",
        "PASSWORD =  \"*******\" #POLITO PASSWORD\n",
        "COURSE_TITLE = \"*********\"\n",
        "LECTURE_TITLE = \"********\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WprGY38WTXvV"
      },
      "source": [
        "### Installation of Dependencies and Environment Setup\n",
        "In the next block, we will install the necessary dependencies and set up the environment to run the subsequent code. This includes installing libraries such as Whisper, MoviePy, Transformers, Selenium, and others, as well as configuring the Chromium browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuAaK2kH6SZZ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "total_time = 0\n",
        "start_time = time.time()\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install moviepy\n",
        "!pip install --upgrade transformers torch\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install selenium webdriver_manager requests\n",
        "!apt-get update -y\n",
        "!apt-get install -y chromium-browser\n",
        "!apt-get install -y chromedriver\n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_7vIARUyXg"
      },
      "source": [
        "# Automated Login and Video Download from Virtual Classroom\n",
        "\n",
        "This script uses Selenium to automate the login to the Politecnico di Torino portal, navigate through the platform, and download the lecture video from the Virtual Classroom. The process includes:\n",
        "\n",
        "1. Automatic login to the PoliTo portal with credentials.\n",
        "2. Navigation to the specified course and desired lecture.\n",
        "3. Extraction of the video URL from the lecture page.\n",
        "4. Downloading the video as an MP4 file to the local system.\n",
        "\n",
        "The browser is run in headless mode (without a graphical interface) for faster processing and without the need for manual interaction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5u_KDGjA57U"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Settings to use Chromium in headless mode\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')  # Headless mode\n",
        "chrome_options.add_argument('--no-sandbox')  # Necessary for running in a container environment\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # Necessary to avoid memory issues\n",
        "\n",
        "# Configure the Chromium driver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# URL and credentials\n",
        "URL = \"https://idp.polito.it/home\"\n",
        "USERNAME_FIELD_ID = \"username\"\n",
        "PASSWORD_FIELD_ID = \"password\"\n",
        "LOGIN_BUTTON_CSS_SELECTOR = \"button.login.button\"\n",
        "\n",
        "# Maximize the window\n",
        "driver.maximize_window()\n",
        "\n",
        "try:\n",
        "    # Open the login page\n",
        "    driver.get(URL)\n",
        "\n",
        "    # Find the username field and enter the value\n",
        "    username_box = driver.find_element(By.ID, USERNAME_FIELD_ID)\n",
        "    username_box.send_keys(USERNAME)\n",
        "\n",
        "    # Find the password field and enter the value\n",
        "    password_box = driver.find_element(By.ID, PASSWORD_FIELD_ID)\n",
        "    password_box.send_keys(PASSWORD)\n",
        "\n",
        "    # Find and click the login button\n",
        "    login_button = driver.find_element(By.CSS_SELECTOR, LOGIN_BUTTON_CSS_SELECTOR)\n",
        "    login_button.click()\n",
        "\n",
        "    # Wait 10 seconds for the page to load\n",
        "    time.sleep(10)\n",
        "\n",
        "    if(driver.title == \"Portale della Didattica - Studente\"):\n",
        "      print(\"Login Completed \")\n",
        "    else:\n",
        "      print(\"Login Failed\")\n",
        "      driver.quit()\n",
        "\n",
        "    if \"MyPoli\" in driver.title:\n",
        "        link_portale = driver.get(\"https://didattica.polito.it/pls/portal30/sviluppo.pagina_studente_2016.main\")\n",
        "\n",
        "\n",
        "    # Print the page title for verification\n",
        "    print(\"Page title:\", driver.title)\n",
        "\n",
        "    # Navigate to the specified course using the course title\n",
        "    link_Course = driver.find_element(By.LINK_TEXT, COURSE_TITLE)\n",
        "    link_Course.click()\n",
        "\n",
        "    # Click the link for the \"Virtual classroom\"\n",
        "    link_virtualClass = driver.find_element(By.LINK_TEXT, \"Virtual classroom\")\n",
        "    link_virtualClass.click()\n",
        "\n",
        "    # Find and click the link for the specific lecture \"Efficient fine-tuning, inference\"\n",
        "    link_vc = driver.find_element(By.XPATH, f\"//a[text()='{LECTURE_TITLE}']\")\n",
        "    link_vc.click()\n",
        "\n",
        "    # Wait 10 seconds for the video to load\n",
        "    time.sleep(10)\n",
        "\n",
        "    # Find the video element using the class 'video-js' and get the video URL\n",
        "    video_element = driver.find_element(By.CLASS_NAME, \"video-js\")\n",
        "    video_url = video_element.find_element(By.TAG_NAME, \"source\").get_attribute(\"src\")\n",
        "\n",
        "    # Download the video using the obtained URL\n",
        "    print(f\"Video URL found: {video_url}\")\n",
        "    video_response = requests.get(video_url)\n",
        "\n",
        "    # Save the video to disk with the name \"video.mp4\"\n",
        "    with open(\"video.mp4\", \"wb\") as video_file:\n",
        "        video_file.write(video_response.content)\n",
        "    print(\"Video downloaded successfully!\")\n",
        "\n",
        "    # Print the page title for verification\n",
        "    print(\"Page title:\", driver.title)\n",
        "\n",
        "finally:\n",
        "    # Wait 10 seconds to see the result\n",
        "    time.sleep(10)\n",
        "    # Close the browser\n",
        "    driver.quit()\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9qL02qCVHHa"
      },
      "source": [
        "# Extracting Audio from Video and Transcription with Whisper\n",
        "\n",
        "This script uses `moviepy` to extract audio from a video file and save it as an MP3 file, then uses OpenAI's Whisper model for potential transcription. The process includes:\n",
        "\n",
        "1. Loading the video file in MP4 format.\n",
        "2. Extracting the audio and saving it as an MP3 file.\n",
        "3. Optionally, using Whisper for audio transcription (not included in this snippet but could be added).\n",
        "   \n",
        "The result is an MP3 file that contains the audio from the video, ready for further processing or transcription.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIVno5is6xJx"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import *\n",
        "import whisper\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"small\")  # Load the model on the appropriate device\n",
        "\n",
        "# Path to the MP4 file\n",
        "input_file = \"video.mp4\"\n",
        "# Name of the output MP3 file\n",
        "output_file = \"audio.mp3\"\n",
        "\n",
        "# Load the video\n",
        "video = VideoFileClip(input_file)\n",
        "\n",
        "# Extract the audio and save it as MP3\n",
        "video.audio.write_audiofile(output_file)\n",
        "\n",
        "print(f\"Conversion completed! File saved as: {output_file}\")\n",
        "\n",
        "# End the timer and calculate the total time\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total operation time: {total_time:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_STGCwuqVeL8"
      },
      "source": [
        "# Audio Transcription with Whisper\n",
        "\n",
        "This script uses OpenAI's Whisper model to transcribe audio from an MP3 file into text. The process includes:\n",
        "\n",
        "1. Loading the audio file in MP3 format.\n",
        "2. Transcribing the audio using the Whisper model.\n",
        "3. Saving the transcription as a text file.\n",
        "\n",
        "The result is a text file containing the full transcription of the audio, ready for review or further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRcsGt4x6eDT"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "# Path to the MP3 file\n",
        "input_audio = \"audio.mp3\"\n",
        "# Name of the output file\n",
        "output_text = \"trascription.txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "result = model.transcribe(input_audio)\n",
        "\n",
        "# Save the transcription to a text file\n",
        "with open(output_text, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(result[\"text\"])\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qcw1VLQVxP6"
      },
      "source": [
        "# Text Summarization with LLama 3.2\n",
        "\n",
        "This script uses the LLama 3.2 model from Hugging Face's Transformers library to generate a summary of a given transcription. The process includes:\n",
        "\n",
        "1. Reading the transcription text from a file.\n",
        "2. Loading the LLama model for summarization (`meta-llama/Llama-3.2-3B-Instruct`).\n",
        "3. Preparing the content for summarization.\n",
        "\n",
        "This script sets up the model and tokenizer, ready to summarize the transcription text into a concise version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL8KBj-GAQ3q"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# Caricamento modello con ottimizzazioni\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "# Verifica dispositivo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IASJ4PjSWU_K"
      },
      "source": [
        "## Llama 3.2 3B Lecture Summarization Script Documentation\n",
        "\n",
        "This script generates a summary for a large transcription using the LLaMA 3.2 family model, which supports an extended context window. The prompt is structured to ensure an academic and coherent summary by enforcing a continuous prose style, organized sections, and clear transitions. It maintains an academic tone, limits paragraph length for readability, and excludes irrelevant details. Mathematical content is formatted with LaTeX, while conceptual continuity is reinforced through structured derivations and applied examples. These elements contribute to producing high-quality, logically structured summaries suitable for lecture material.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGun1enwE8Ll"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Lettura file\n",
        "file_path = \"trascription.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    transcription_text = file.read()\n",
        "\n",
        "# Costruzione prompt ottimizzato\n",
        "system_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "You are a technical writer creating comprehensive lecture summaries. Structure your output in continuous prose with these sections:\n",
        "\n",
        "**Formatting Rules:**\n",
        "1. Never use bullet points or numbered lists\n",
        "2. Use subheadings with ## notation\n",
        "3. Keep paragraphs under 10 sentences\n",
        "4. Maintain third-person academic tone\n",
        "5. Explicitly mention when transitioning between topics\n",
        "6. Include pratical examples\n",
        "7. Keep a connections between the different parts\n",
        "8. Exclude useless information\n",
        "9. Use transitional phrases:\n",
        "   - 'Building upon the previous discussion of X...'\n",
        "   - 'This finding naturally leads to consideration of Y...'\n",
        "10. Create conceptual bridges between sections using:\n",
        "   - Mathematical continuity (derive Equation 2 from Equation 1)\n",
        "   - Applied case studies demonstrating theoretical principles\n",
        "11. Enclose equations in \\( \\) for inline and \\[ \\] for display\n",
        "12. Use LaTeX environments for multi-line proofs:\n",
        "   \\[\n",
        "   \\begin{align}\n",
        "       x &= \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\\\\n",
        "       \\frac{dy}{dx} &= 3x^2 + 2x\n",
        "   \\end{align}\n",
        "   \\]\n",
        "\n",
        "<|eot_id|>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "user_prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\n",
        "{transcription_text}<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "# Tokenizzazione con gestione lunghezza\n",
        "inputs = tokenizer(\n",
        "    system_prompt + user_prompt,\n",
        "    return_tensors=\"pt\",\n",
        ").to(device)\n",
        "\n",
        "# Generazione con parametri ottimizzati\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=2048,\n",
        "        min_new_tokens=512,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.1,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "# Decodifica e pulizia output\n",
        "full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "summary = full_text.split(\"Output:\")[1].strip()\n",
        "\n",
        "# Salvataggio risultati\n",
        "total_time = time.time() - start_time\n",
        "with open(\"final_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"Lecture Summary:\\n{summary}\\n\")\n",
        "    f.write(f\"\\nGeneration time: {total_time:.2f} seconds\")\n",
        "\n",
        "print(f\"Riassunto completato in {total_time:.2f} secondi\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJvvbqcsAQoL"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bx5rBfgTUBW"
      },
      "source": [
        "#PolitoSbobinatore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WprGY38WTXvV"
      },
      "source": [
        "### Installation of Dependencies and Environment Setup\n",
        "In the next block, we will install the necessary dependencies and set up the environment to run the subsequent code. This includes installing libraries such as Whisper, MoviePy, Transformers, Selenium, and others, as well as configuring the Chromium browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuAaK2kH6SZZ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "total_time = 0\n",
        "start_time = time.time()\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install moviepy \n",
        "!pip install --upgrade transformers torch\n",
        "!pip install torch \n",
        "!pip install transformers  \n",
        "!pip install selenium webdriver_manager requests\n",
        "!apt-get update -y\n",
        "!apt-get install -y chromium-browser\n",
        "!apt-get install -y chromedriver\n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqbQTe4zUFFc"
      },
      "source": [
        "# Insert Your Polito Credentials and Course Information\n",
        "\n",
        "Before running the script, fill in your PoliTo credentials and the course details:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "z3XRf9ZHOmIM"
      },
      "outputs": [],
      "source": [
        "#INSERT HERE YOUR DATA\n",
        "USERNAME = \"****\" #POLITO USERNAME\n",
        "PASSWORD =  \"****\" #POLITO PASSWORD\n",
        "COURSE_TITLE = \"*****\" #COURSE TITLE\n",
        "LECTURE_TITLE = \"******\" #LECTURE TITLE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO_7vIARUyXg"
      },
      "source": [
        "# Automated Login and Video Download from Virtual Classroom\n",
        "\n",
        "This script uses Selenium to automate the login to the Politecnico di Torino portal, navigate through the platform, and download the lecture video from the Virtual Classroom. The process includes:\n",
        "\n",
        "1. Automatic login to the PoliTo portal with credentials.\n",
        "2. Navigation to the specified course and desired lecture.\n",
        "3. Extraction of the video URL from the lecture page.\n",
        "4. Downloading the video as an MP4 file to the local system.\n",
        "\n",
        "The browser is run in headless mode (without a graphical interface) for faster processing and without the need for manual interaction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5u_KDGjA57U"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Settings to use Chromium in headless mode\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')  # Headless mode\n",
        "chrome_options.add_argument('--no-sandbox')  # Necessary for running in a container environment\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # Necessary to avoid memory issues\n",
        "\n",
        "# Configure the Chromium driver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# URL and credentials\n",
        "URL = \"https://idp.polito.it/home\"\n",
        "USERNAME_FIELD_ID = \"username\"\n",
        "PASSWORD_FIELD_ID = \"password\"\n",
        "LOGIN_BUTTON_CSS_SELECTOR = \"button.login.button\"\n",
        "\n",
        "# Maximize the window\n",
        "driver.maximize_window()\n",
        "\n",
        "try:\n",
        "    # Open the login page\n",
        "    driver.get(URL)\n",
        "\n",
        "    # Find the username field and enter the value\n",
        "    username_box = driver.find_element(By.ID, USERNAME_FIELD_ID)\n",
        "    username_box.send_keys(USERNAME)\n",
        "\n",
        "    # Find the password field and enter the value\n",
        "    password_box = driver.find_element(By.ID, PASSWORD_FIELD_ID)\n",
        "    password_box.send_keys(PASSWORD)\n",
        "\n",
        "    # Find and click the login button\n",
        "    login_button = driver.find_element(By.CSS_SELECTOR, LOGIN_BUTTON_CSS_SELECTOR)\n",
        "    login_button.click()\n",
        "\n",
        "    # Wait 10 seconds for the page to load\n",
        "    time.sleep(10)\n",
        "\n",
        "    if(driver.title == \"Portale della Didattica - Studente\"):\n",
        "      print(\"Login Completed \")\n",
        "    else:\n",
        "      print(\"Login Failed\")\n",
        "      driver.quit()\n",
        "\n",
        "    if \"MyPoli\" in driver.title:\n",
        "        link_portale = driver.get(\"https://didattica.polito.it/pls/portal30/sviluppo.pagina_studente_2016.main\")\n",
        "\n",
        "\n",
        "    # Print the page title for verification\n",
        "    print(\"Page title:\", driver.title)\n",
        "\n",
        "    # Navigate to the specified course using the course title\n",
        "    link_Course = driver.find_element(By.LINK_TEXT, COURSE_TITLE)\n",
        "    link_Course.click()\n",
        "\n",
        "    # Click the link for the \"Virtual classroom\"\n",
        "    link_virtualClass = driver.find_element(By.LINK_TEXT, \"Virtual classroom\")\n",
        "    link_virtualClass.click()\n",
        "\n",
        "    # Find and click the link for the specific lecture \"Efficient fine-tuning, inference\"\n",
        "    link_vc = driver.find_element(By.XPATH, f\"//a[text()='{LECTURE_TITLE}']\")\n",
        "    link_vc.click()\n",
        "\n",
        "    # Wait 10 seconds for the video to load\n",
        "    time.sleep(10)\n",
        "\n",
        "    # Find the video element using the class 'video-js' and get the video URL\n",
        "    video_element = driver.find_element(By.CLASS_NAME, \"video-js\")\n",
        "    video_url = video_element.find_element(By.TAG_NAME, \"source\").get_attribute(\"src\")\n",
        "\n",
        "    # Download the video using the obtained URL\n",
        "    print(f\"Video URL found: {video_url}\")\n",
        "    video_response = requests.get(video_url)\n",
        "\n",
        "    # Save the video to disk with the name \"video.mp4\"\n",
        "    with open(\"video.mp4\", \"wb\") as video_file:\n",
        "        video_file.write(video_response.content)\n",
        "    print(\"Video downloaded successfully!\")\n",
        "\n",
        "    # Print the page title for verification\n",
        "    print(\"Page title:\", driver.title)\n",
        "\n",
        "finally:\n",
        "    # Wait 10 seconds to see the result\n",
        "    time.sleep(10)\n",
        "    # Close the browser\n",
        "    driver.quit()\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9qL02qCVHHa"
      },
      "source": [
        "# Extracting Audio from Video and Transcription with Whisper\n",
        "\n",
        "This script uses `moviepy` to extract audio from a video file and save it as an MP3 file, then uses OpenAI's Whisper model for potential transcription. The process includes:\n",
        "\n",
        "1. Loading the video file in MP4 format.\n",
        "2. Extracting the audio and saving it as an MP3 file.\n",
        "3. Optionally, using Whisper for audio transcription (not included in this snippet but could be added).\n",
        "   \n",
        "The result is an MP3 file that contains the audio from the video, ready for further processing or transcription.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIVno5is6xJx"
      },
      "outputs": [],
      "source": [
        "from moviepy import *\n",
        "import whisper\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"small\")  # Load the model on the appropriate device\n",
        "\n",
        "# Path to the MP4 file\n",
        "input_file = \"video.mp4\"\n",
        "# Name of the output MP3 file\n",
        "output_file = \"audio.mp3\"\n",
        "\n",
        "# Load the video\n",
        "video = VideoFileClip(input_file)\n",
        "\n",
        "# Extract the audio and save it as MP3\n",
        "video.audio.write_audiofile(output_file)\n",
        "\n",
        "print(f\"Conversion completed! File saved as: {output_file}\")\n",
        "\n",
        "# End the timer and calculate the total time\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time\n",
        "print(f\"Total operation time: {total_time:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_STGCwuqVeL8"
      },
      "source": [
        "# Audio Transcription with Whisper\n",
        "\n",
        "This script uses OpenAI's Whisper model to transcribe audio from an MP3 file into text. The process includes:\n",
        "\n",
        "1. Loading the audio file in MP3 format.\n",
        "2. Transcribing the audio using the Whisper model.\n",
        "3. Saving the transcription as a text file.\n",
        "\n",
        "The result is a text file containing the full transcription of the audio, ready for review or further processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RRcsGt4x6eDT"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "# Path to the MP3 file\n",
        "input_audio = \"audio.mp3\"\n",
        "# Name of the output file\n",
        "output_text = \"trascription.txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "result = model.transcribe(input_audio)\n",
        "\n",
        "# Save the transcription to a text file\n",
        "with open(output_text, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(result[\"text\"])\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = total_time + end_time - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qcw1VLQVxP6"
      },
      "source": [
        "# Text Summarization with BART\n",
        "\n",
        "This script uses the BART model from Hugging Face's Transformers library to generate a summary of a given transcription. The process includes:\n",
        "\n",
        "1. Reading the transcription text from a file.\n",
        "2. Loading the BART model for summarization (`facebook/bart-large-cnn`).\n",
        "3. Preparing the content for summarization.\n",
        "\n",
        "This script sets up the model and tokenizer, ready to summarize the transcription text into a concise version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL8KBj-GAQ3q"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Check if a GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available, otherwise use CPU\n",
        "print(f\"Using device: {device}\")  # Print which device is being used (GPU or CPU)\n",
        "\n",
        "start_time = time.time()  # Start measuring the time to load the model\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "print(\"Loading the BART model for summarization...\")  # Notify that model loading has started\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')  # Load the tokenizer\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)  # Load the model and move it to the device (GPU/CPU)\n",
        "\n",
        "end_time = time.time()  # End measuring the time\n",
        "\n",
        "# Calculate the total time taken for loading the model and processing\n",
        "total_time = total_time + end_time - start_time\n",
        "print(f\"Time taken to load the model and process the file: {total_time:.4f} seconds\")  # Print the total time taken\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IASJ4PjSWU_K"
      },
      "source": [
        "# Chunk-Based Summarization of Transcription with BART\n",
        "\n",
        "This script generates a summary for a large transcription by breaking it into smaller chunks, each of which is summarized separately. The process includes:\n",
        "\n",
        "1. Splitting the transcription text into chunks of a maximum length (1024 characters).\n",
        "2. Using the BART model to summarize each chunk with the context of previous summaries.\n",
        "3. Concatenating the individual summaries to create the final summarized text.\n",
        "4. Saving the final summary as a text file.\n",
        "\n",
        "This approach ensures that even long transcriptions can be summarized efficiently while maintaining coherence across chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGun1enwE8Ll"
      },
      "outputs": [],
      "source": [
        "# File name to read\n",
        "file_path = \"trascription.txt\"\n",
        "\n",
        "# Open and read the content of the file\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "transcription_text = content\n",
        "start_time = time.time()  # Start the timer to measure the total operation time.\n",
        "\n",
        "# Maximum length for each chunk in tokens\n",
        "max_length = 1024\n",
        "max_length_chunk = 900  # Maximum length for a single chunk in tokens.\n",
        "\n",
        "# Tokenize the full transcription text without truncation to calculate its total length.\n",
        "prompt_tokenized_test = tokenizer(transcription_text, return_tensors=\"pt\", truncation=False, padding=True)\n",
        "len_p = prompt_tokenized_test[\"input_ids\"].shape[1]  # Get the total number of tokens in the text.\n",
        "\n",
        "# Calculate the number of chunks based on the maximum chunk length.\n",
        "N = len_p // max_length_chunk\n",
        "text_length = len(transcription_text)\n",
        "chunk_size = text_length // N  # Calculate approximate character length per chunk.\n",
        "\n",
        "# Split the text into N equal parts.\n",
        "chunks = [transcription_text[i:i + chunk_size] for i in range(0, text_length, chunk_size)]\n",
        "\n",
        "# Ensure the last chunk contains any remaining characters.\n",
        "if len(chunks) > N:\n",
        "    chunks[-2] += chunks[-1]  # Merge the last chunk with the second last.\n",
        "    chunks = chunks[:-1]  # Remove the last (now empty) chunk.\n",
        "\n",
        "# List to store the summaries of each chunk.\n",
        "summaries = []\n",
        "\n",
        "# Process each chunk to generate summaries.\n",
        "for i, chunk in enumerate(chunks):\n",
        "    # Create a prompt for summarization including the context of the previous summary.\n",
        "    prompt = f\"\"\"\n",
        "    {chunk}\n",
        "    \"\"\"\n",
        "    # Tokenize the prompt and move it to the GPU.\n",
        "    prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=1024).to(device)\n",
        "\n",
        "    minThreshold = int((i / len(chunks)) * 1000)  # Gradually increase the minimum threshold for summary length.\n",
        "\n",
        "    # Generate the summary using the model with adjusted parameters\n",
        "    outputs = model.generate(\n",
        "        prompt_tokenized[\"input_ids\"],\n",
        "        max_length=1024,  # Maximum length for the summary\n",
        "        min_length=300,  # Increase the minimum length to ensure more detail\n",
        "        do_sample=True,  # Enable sampling for more variability in the output\n",
        "        temperature=0.2,  # Set temperature higher for more diversity in the responses\n",
        "        top_p=0.9,  # Increase top_p to consider a wider pool of tokens\n",
        "        length_penalty=1.0,  # Control length penalties to avoid very short outputs\n",
        "    )\n",
        "\n",
        "    # Decode the generated summary and append it to the summaries list.\n",
        "    new_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    summaries.append(new_summary)\n",
        "\n",
        "    # Update the context with the latest summary for the next chunk.\n",
        "\n",
        "    print(f\"Processed chunk [{i + 1}/{len(chunks)}]\")\n",
        "\n",
        "# End the timer.\n",
        "end_time = time.time()\n",
        "# Calculate the total operation time.\n",
        "total_time = total_time + end_time - start_time\n",
        "\n",
        "# Save all chunk summaries to a separate file.\n",
        "joined_output_path = \"final_summary.txt\"\n",
        "with open(joined_output_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    for i, summary in enumerate(summaries, start=1):\n",
        "        file.write(summary)\n",
        "        file.write(\"\\n\")  # Add a blank line between summaries.\n",
        "    file.write(f\"The total operation is completed in: {int(total_time // 60)} minutes and {total_time % 60:.2f} seconds\")\n",
        "\n",
        "\n",
        "print(f\"Summary completed! Final summaries saved in: {joined_output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJvvbqcsAQoL"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
